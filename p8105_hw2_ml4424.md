p8105\_hw2\_ml4424
================
Maggie Li (ml4424)
9/28/2020

## Read in libraries

``` r
library(readxl)
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.1     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.1     ✓ dplyr   1.0.0
    ## ✓ tidyr   1.1.0     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

## Problem 1

``` r
trash = read_excel("prob1_data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                   sheet = "Mr. Trash Wheel",
                   cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(year) %>% #drop rows with NAs that are just totals; not dumpster-specific
  mutate(rnd_sb = as.integer(round(sports_balls, 0)))
  
trash
```

    ## # A tibble: 344 x 15
    ##    dumpster month  year date                weight_tons volume_cubic_ya…
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>            <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31               18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74               13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45               15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06               18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71               13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52               14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76               18
    ## # … with 334 more rows, and 9 more variables: plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <dbl>,
    ## #   homes_powered <dbl>, rnd_sb <int>

``` r
precip_17 = read_excel("prob1_data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                   sheet = "2017 Precipitation",
                   skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017)
  
precip_17
```

    ## # A tibble: 12 x 3
    ##    month total  year
    ##    <dbl> <dbl> <dbl>
    ##  1     1  2.34  2017
    ##  2     2  1.46  2017
    ##  3     3  3.57  2017
    ##  4     4  3.99  2017
    ##  5     5  5.64  2017
    ##  6     6  1.4   2017
    ##  7     7  7.09  2017
    ##  8     8  4.44  2017
    ##  9     9  1.95  2017
    ## 10    10  0     2017
    ## 11    11  0.11  2017
    ## 12    12  0.94  2017

``` r
precip_18 = read_excel("prob1_data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                   sheet = "2018 Precipitation",
                   skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018)
  
precip_18
```

    ## # A tibble: 12 x 3
    ##    month total  year
    ##    <dbl> <dbl> <dbl>
    ##  1     1  0.94  2018
    ##  2     2  4.8   2018
    ##  3     3  2.69  2018
    ##  4     4  4.69  2018
    ##  5     5  9.27  2018
    ##  6     6  4.77  2018
    ##  7     7 10.2   2018
    ##  8     8  6.45  2018
    ##  9     9 10.5   2018
    ## 10    10  2.12  2018
    ## 11    11  7.82  2018
    ## 12    12  6.11  2018

``` r
# bind tbls
precip_17_18 <- bind_rows(precip_17, precip_18) %>%
  mutate(month = month.name[month])
precip_17_18
```

    ## # A tibble: 24 x 3
    ##    month     total  year
    ##    <chr>     <dbl> <dbl>
    ##  1 January    2.34  2017
    ##  2 February   1.46  2017
    ##  3 March      3.57  2017
    ##  4 April      3.99  2017
    ##  5 May        5.64  2017
    ##  6 June       1.4   2017
    ##  7 July       7.09  2017
    ##  8 August     4.44  2017
    ##  9 September  1.95  2017
    ## 10 October    0     2017
    ## # … with 14 more rows

``` r
# total precip in 2018
tot_precip_18 <- precip_18 %>% summarize(sum(total))

# median sports balls in dumpster in 2017 (i assume we are pulling from the rounded sports ball column)
median_sb <- trash %>% filter(year == 2017) %>%
  summarize(median(rnd_sb))
median_sb
```

    ## # A tibble: 1 x 1
    ##   `median(rnd_sb)`
    ##              <int>
    ## 1                8

**Description of Mr. Trash Wheel and Precipitation Data:** The Mr. Trash
Wheel data are formatted so that each entry specifies a dumpster filled
by the vessel, including the date which a full dumpster of trash was
collected and columns with details on the waste weight, volume and
materials composition, as well as homes powered when the dumpster is
transported to a waste-to-energy plant to create electricity. There are
344 observations, meaning there have been 344 dumpsters filled by the
contraption between May 2014 and June 2019.

The precipitation data for 2017 and 2018 contain monthly precipitation
(inches of rainfall). There are 24 observations in the data, one row for
every month in these two years. The total precipitation was 70.33
inches. The mean number of sports balls collected in a dumpster in 2017
was
8.

## Problem 2

``` r
transit_dta <- read_csv("prob2_data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  dplyr::select(line, station_name, station_latitude, station_longitude, starts_with("route"),
                entry, vending, entrance_type, ada) %>% # select relevant p columns
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) # logical vector
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
transit_dta
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu… route1 route2 route3
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  2 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  3 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  4 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  5 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  6 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  7 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  8 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  9 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ## 10 4 Av… 53rd St                  40.6            -74.0 R      <NA>   <NA>  
    ## # … with 1,858 more rows, and 12 more variables: route4 <chr>, route5 <chr>,
    ## #   route6 <chr>, route7 <chr>, route8 <dbl>, route9 <dbl>, route10 <dbl>,
    ## #   route11 <dbl>, entry <lgl>, vending <chr>, entrance_type <chr>, ada <lgl>

**Description:** These data describe NYC subway station characteristics.
In the cleaned data, each row represents a unique subway station’s
entrance or exit in NYC. From the raw data, we have kept relevant
identifying information on the subway line served, the name of the
station, the latitude and longitude coordinates, the routes served by
the specific station, whether or not a specific entrance/exit allows
entry or is just exit-only, the mode of entrance into the station, and
whether or not it is ADA compliant. We further cleaned the data by
converting entry to a logical T/F given whether or not the entrance
allows entry (TRUE) or is exit-only (FALSE). The dimensions are 1,868
rows by 19 columns. These data are not tidy; the route information is
spread across 11 columns.

``` r
# distinct stations
distinct_stn <- distinct(transit_dta, line, station_name) %>% nrow()

# number of ADA compliant stations (up one level from entrance/exits at stations)
ADA_comp <- transit_dta %>% 
  select(line, station_name, ada) %>% # drop all other columns of station sublevels, only interested in station-level attributes
  distinct() %>% 
  filter(ada == T) %>% nrow()
ADA_comp
```

    ## [1] 84

``` r
# proportion of entrance/exits without vending allow entrance
entry_no_vend <- transit_dta %>% 
  filter(vending == "NO", 
         entry == T) %>% nrow()
```

There are 465 distinct stations. Out of these stations, 84 are
ADA-compliant. Of all station entrance/exits without vending, 69 allow
entrance.

``` r
tidy_transit <- transit_dta %>% 
  mutate_if(is.numeric, as.character) %>%  # convert numeric route columns to characters to avoid errors later
  pivot_longer(route1:route11,
               names_to = "route",
               values_to = "route_name") %>%
  drop_na() %>%  # drop NA rows, these are extra rows that don't contain route at specific station entrance/exit when we tidied data
  distinct(line, station_name, route_name,
           .keep_all = TRUE) # pull distinct line, station_name, and routes at these stations
tidy_transit
```

    ## # A tibble: 981 x 10
    ##    line  station_name station_latitude station_longitu… entry vending
    ##    <chr> <chr>        <chr>            <chr>            <lgl> <chr>  
    ##  1 4 Av… 25th St      40.660397        -73.998091       TRUE  YES    
    ##  2 4 Av… 36th St      40.655144        -74.003549       TRUE  YES    
    ##  3 4 Av… 36th St      40.655144        -74.003549       TRUE  YES    
    ##  4 4 Av… 45th St      40.648939        -74.010006       TRUE  YES    
    ##  5 4 Av… 53rd St      40.645069        -74.014034       TRUE  YES    
    ##  6 4 Av… 59th St      40.641362        -74.017881       TRUE  YES    
    ##  7 4 Av… 59th St      40.641362        -74.017881       TRUE  YES    
    ##  8 4 Av… 77th St      40.629742        -74.02551        TRUE  YES    
    ##  9 4 Av… 86th St      40.622687        -74.028398       TRUE  YES    
    ## 10 4 Av… 95th St      40.616622        -74.030876       TRUE  YES    
    ## # … with 971 more rows, and 4 more variables: entrance_type <chr>, ada <lgl>,
    ## #   route <chr>, route_name <chr>

``` r
# how many distinct stations serve the A train
A_stns <- tidy_transit %>% filter(route_name == "A") 

# ADA compliant A train stations
ADA_A_stns <- A_stns %>% filter(ada == TRUE) %>% nrow()
ADA_A_stns
```

    ## [1] 17

There are 60 that serve the A train. Of these stations, 17 are ADA
compliant.

## Problem 3

``` r
pols <- read_csv("prob3_data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "date")) %>%
  mutate(month = month.name[as.integer(month)]) %>% # replace month number with month name
  pivot_longer(cols = starts_with("prez"),
               names_to = "president",
               values_to = "party",
               names_prefix = "prez_") %>% # wide to long format for president & party
  filter(party >= 1) %>% # we've duplicated each month/year combination, so we want to get rid of duplicates                           
                          # (party = 0); i.e. keep 1 (yes) and weird 2 values during Watergate(?)
  select(-date, -party) # only keep year and month as leading key cols
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols
```

    ## # A tibble: 822 x 9
    ##    year  month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <chr> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1 1947  January        23      51     253      23      45     198 dem      
    ##  2 1947  February       23      51     253      23      45     198 dem      
    ##  3 1947  March          23      51     253      23      45     198 dem      
    ##  4 1947  April          23      51     253      23      45     198 dem      
    ##  5 1947  May            23      51     253      23      45     198 dem      
    ##  6 1947  June           23      51     253      23      45     198 dem      
    ##  7 1947  July           23      51     253      23      45     198 dem      
    ##  8 1947  August         23      51     253      23      45     198 dem      
    ##  9 1947  September      23      51     253      23      45     198 dem      
    ## 10 1947  October        23      51     253      23      45     198 dem      
    ## # … with 812 more rows

``` r
snp <- read_csv("prob3_data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, c("month", "date", "year")) %>%
  select(year, month, close) %>%
  mutate(month = month.name[as.integer(month)])
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
snp
```

    ## # A tibble: 787 x 3
    ##    year  month    close
    ##    <chr> <chr>    <dbl>
    ##  1 2015  July     2080.
    ##  2 2015  June     2063.
    ##  3 2015  May      2107.
    ##  4 2015  April    2086.
    ##  5 2015  March    2068.
    ##  6 2015  February 2104.
    ##  7 2015  January  1995.
    ##  8 2014  December 2059.
    ##  9 2014  November 2068.
    ## 10 2014  October  2018.
    ## # … with 777 more rows

``` r
unemployment <- read_csv("prob3_data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>%
  rename_at(vars(tolower(month.abb)), ~month.name) %>% 
  pivot_longer(January:December,
               names_to = "month") %>% 
  mutate(year = as.character(year)) # coerce year to character to match previous datasets
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
unemployment
```

    ## # A tibble: 816 x 3
    ##    year  month     value
    ##    <chr> <chr>     <dbl>
    ##  1 1948  January     3.4
    ##  2 1948  February    3.8
    ##  3 1948  March       4  
    ##  4 1948  April       3.9
    ##  5 1948  May         3.5
    ##  6 1948  June        3.6
    ##  7 1948  July        3.6
    ##  8 1948  August      3.9
    ##  9 1948  September   3.8
    ## 10 1948  October     3.7
    ## # … with 806 more rows

``` r
# merge snp to pols and merge unemployment into this
joined_dta <- left_join(pols, snp) %>% left_join(unemployment)
```

    ## Joining, by = c("year", "month")
    ## Joining, by = c("year", "month")

``` r
joined_dta
```

    ## # A tibble: 822 x 11
    ##    year  month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <chr> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1 1947  Janu…      23      51     253      23      45     198 dem          NA
    ##  2 1947  Febr…      23      51     253      23      45     198 dem          NA
    ##  3 1947  March      23      51     253      23      45     198 dem          NA
    ##  4 1947  April      23      51     253      23      45     198 dem          NA
    ##  5 1947  May        23      51     253      23      45     198 dem          NA
    ##  6 1947  June       23      51     253      23      45     198 dem          NA
    ##  7 1947  July       23      51     253      23      45     198 dem          NA
    ##  8 1947  Augu…      23      51     253      23      45     198 dem          NA
    ##  9 1947  Sept…      23      51     253      23      45     198 dem          NA
    ## 10 1947  Octo…      23      51     253      23      45     198 dem          NA
    ## # … with 812 more rows, and 1 more variable: value <dbl>

**Description**: The pols dataset contains 822 rows for each month in
every year between January 1947 and June 2015 (68 years \* 12 months + 6
months), and several columns for number of republican or democratic
governors, national senators and representatives, and two columns
signifying whether or not the sitting president was dem or gop (1/0)
that month. We mutated the data so that *president* was the identifying
column, and dem or gop were the potential values for this column. The
final dimensions were 822 x 9.

The snp data contain 787 rows for each month in every year between
January 1950 and July 2015 (65 years \* 12 months + 7 months), and a
column indicating the closing values of the S\&P stock on a specified
date during the observation month, between the 1st and 4th date of the
month. We transformed the data so it would be in the same format as the
pols dataset, parsing out the *date* column into *year* and *month* and
replacing month number with month name. The final dimensions were 787 x
3.

The final unemployment data contains the unemployment rate for every
month between January 1948 and December 2015. In the original data,
there were 68 rows for each of these 68 years, with columns indicating
the unemployment rate for each month of the year. We tidied this data so
that every row instead was a month of a given year and the final
dimension was n = 816 (68 years \* 12 months), and the *value* column
indicated that monthly unemployment rate. The final dimensions were 816
x 3.

We were able to join all three datasets on key variables *year* and
*month*. In the final joined dataset, we had 822 rows from the pols
dataset, so every row represented a month within the study period
between January 1947 and June 2015, with additional columns for monthly
S\&P stock data and unemployment rate which we joined to the pols data.
There are NA values for the months that were missing S\&P and/or
unemployment data in 1947-1949.
